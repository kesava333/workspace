import json
import boto3
import re
import uuid
import time
import random
from datetime import datetime, timedelta
import os
import csv

bucketregion_name='ap-south-1'
# Mention the days to fetch the report in Days from Today
reportPeriod=5
bucketName="report-instancemani"

def lambda_handler(event, context):
    
    time=datetime.now()
    s3client = boto3.client('s3',region_name=bucketregion_name)
    
    header = ['InstanceID', 'Region', 'Status', 'Hours']
    
    statusToCheck='running'
    
    report=[]
    
    def publishing_metrics(data):
            response = cloudwatch.put_metric_data(
               MetricData = [
               {
                    'MetricName': 'InstanceStatus',
                    'Dimensions': [
                        {
                            'Name': str(id),
                            'Value': str(state)
                        },
                     ],
                        'Unit': 'None' ,
                        'Value': data
                },
                ],
                Namespace = 'InstanceStatusReport')
    
    def get_response(iId, iStatus):
            response = cloudwatch.get_metric_statistics(
                    Namespace = 'InstanceStatusReport',
                    Period = 2592000,
                   # StartTime = datetime.utcnow() - timedelta(seconds = 10800),
                    StartTime =  datetime.now() - timedelta(days=reportPeriod),
                    EndTime = datetime.utcnow(),
                    MetricName = 'InstanceStatus',
                     Statistics=[
                    "Sum",
                ],
                    Dimensions = [
                        {'Name': str(iId), 'Value': str(iStatus)}
                    ])
            for r in response['Datapoints']:
                return(iId,region_name['RegionName'],statusToCheck,r['Sum'])
    
    
                
    client = boto3.client('ec2')
    
    for region_name in client.describe_regions()['Regions']:

        
        ec2 = boto3.resource('ec2',region_name=region_name['RegionName'])
        cloudwatch = boto3.client('cloudwatch',region_name=region_name['RegionName'])
        
        for instance in ec2.instances.all():
            id,state=instance.id,instance.state['Name']
            print("Pushing report for instance: "+ id )
        
            if state == 'running' or 'pending':
                publishing_metrics(1)
                print("Instance is Running, Status Updated to cloudwatch")
            elif state == 'stopping' or 'stopped':
                publishing_metrics(0)
                print("Instance is Stopped, Status Updated to cloudwatch")
        
            report.append(get_response(id,state))
        
        temp_csv_file = csv.writer(open("/tmp/csv_file.csv", "w+"))
        temp_csv_file.writerow(["Account Name", "Month", "Cost"])
        
        
        fin_report=[list(dimension) for dimension in list(report)]
        stamp="instanceSummaryReport-"+str(time.year)+"-"+str(time.month)+"-"+str(time.day)+"-"+str(time.hour)+":"+str(time.minute)
        
        with open('/tmp/'+str(stamp)+"."+'csv', 'w', encoding='UTF8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(header)
            
            for data in fin_report:
               writer.writerow(data)
        
        #s3client.upload_file('/tmp/'+str(stamp)+"."+'csv', bucketName, str(stamp)+"."+'csv')
        

 
        #terms = price_item["terms"]
        #term = terms["OnDemand"].itervalues().next()
        
        '''
        price_item = json.loads(price_list[0])
        terms = price_item["terms"]
        term = terms["OnDemand"].itervalues().next()
        
        price_dimension = term["priceDimensions"].itervalues().next()
        price = price_dimension['pricePerUnit']["USD"]
        print(price)
        '''
